{"cells":[{"cell_type":"markdown","metadata":{"id":"OwKLi9JsPXHi"},"source":["### LDA\n","\n","LDA's approach to topic modeling considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion.\n","Once you provide the algorithm with the number of topics, all it does it to rearrange the topics distribution within the documents and keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n","\n","***When we say topic, what is it actually and how it is represented?***\n","\n","A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about.\n","\n","The following are key factors to obtaining good segregation topics:\n","\n","- The quality of text processing.\n","- The variety of topics the text talks about. \n","- The choice of topic modeling algorithm.\n","- The number of topics fed to the algorithm.\n","- The algorithms tuning parameters."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyjXkWDns_5v","executionInfo":{"status":"ok","timestamp":1643888789830,"user_tz":-60,"elapsed":27097,"user":{"displayName":"Francesca Padovani","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16831289911927475598"}},"outputId":"a9f24700-920b-4208-9baf-9fdd118bc602"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install --upgrade gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_GO2dyPafdd","executionInfo":{"status":"ok","timestamp":1643889237066,"user_tz":-60,"elapsed":3057,"user":{"displayName":"Francesca Padovani","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16831289911927475598"}},"outputId":"7291a655-06d3-491f-eebb-ef2396ab4cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n"]}]},{"cell_type":"code","source":["!pip install pyLDAvis==2.1.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":749},"id":"E9-f6otSamiV","executionInfo":{"status":"ok","timestamp":1643889418347,"user_tz":-60,"elapsed":3943,"user":{"displayName":"Francesca Padovani","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16831289911927475598"}},"outputId":"9e2e9db9-f8be-4785-931b-a49d04f3bbe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyLDAvis==2.1.2\n","  Downloading pyLDAvis-2.1.2.tar.gz (1.6 MB)\n","\u001b[?25l\r\u001b[K     |▏                               | 10 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 143 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 163 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 194 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 215 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 225 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 235 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 245 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 256 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 266 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 276 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 286 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 296 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 307 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 317 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 327 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 337 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 358 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 368 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 378 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 389 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 399 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 409 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 419 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 430 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 440 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 450 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 460 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 471 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 481 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 491 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 501 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 512 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 522 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 532 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 542 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 552 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 563 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 573 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 583 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 593 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 604 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 614 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 624 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 634 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 645 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 655 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 665 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 675 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 686 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 696 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 706 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 716 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 727 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 737 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 747 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 757 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 768 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 778 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 788 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 798 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 808 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 819 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 829 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 839 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 849 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 860 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 870 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 880 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 890 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 901 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 911 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 921 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 931 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 942 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 952 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 962 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 972 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 983 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 993 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.0 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6 MB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.37.1)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.21.5)\n","Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.4.1)\n","Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.3.5)\n","Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.1.0)\n","Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.11.3)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.8.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (3.6.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.16.0)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.17)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.0.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.15.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis==2.1.2) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis==2.1.2) (3.0.7)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (8.12.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (57.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (21.4.0)\n","Building wheels for collected packages: pyLDAvis\n","  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97738 sha256=c6570a11332b6395f76dd9a1fed30a73de6511b6603cdbcf0306bae38f318064\n","  Stored in directory: /root/.cache/pip/wheels/3b/fb/41/e32e5312da9f440d34c4eff0d2207b46dc9332a7b931ef1e89\n","Successfully built pyLDAvis\n","Installing collected packages: pyLDAvis\n","  Attempting uninstall: pyLDAvis\n","    Found existing installation: pyLDAvis 3.3.1\n","    Uninstalling pyLDAvis-3.3.1:\n","      Successfully uninstalled pyLDAvis-3.3.1\n","Successfully installed pyLDAvis-2.1.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyLDAvis"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZKiDhzyPO81"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import re\n","import nltk\n","import string\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from zipfile import ZipFile\n","from nltk import sent_tokenize\n","from nltk import word_tokenize\n","from collections import defaultdict\n","import gensim\n","\n","import re\n","import numpy as np\n","import pandas as pd\n","from pprint import pprint\n","\n","# Gensim\n","import gensim\n","from gensim import corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","from gensim.models import TfidfModel\n","from gensim import models\n","# spacy for lemmatization\n","import spacy\n","\n","# Plotting tools\n","import pyLDAvis\n","import pyLDAvis.gensim\n","\n","pyLDAvis.enable_notebook()\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Enable logging for gensim - optional\n","import logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n","\n","import warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBu-wEmmPdLs"},"outputs":[],"source":["#you retrieve data of mental illness posts stored in the zip file on the computer\n","def zip2text(path): \n","    arch_in = ZipFile(mypath, \"r\")\n","    files_name = arch_in.namelist()\n","    out = {}\n","    for file in files_name:\n","        text = arch_in.read(file).decode('utf-8')\n","        article = [sent.split(\" * \") for sent in text.split(\"\\n\")]\n","        out[file] = article\n","    arch_in.close()\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nF7uXluapgHV"},"outputs":[],"source":["#open the zip file (experimental group)\n","mypath = \"/content/drive/MyDrive/Computational_Linguistics_Project /myarchive_illness.zip\" \n","resss = zip2text(mypath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOOncmAZpgHX"},"outputs":[],"source":["#open the zip file (control group)\n","my_second_path = '/Users/FrancescaPadovani/Desktop/MIO_PRO/myarchive_control.zip'\n","resss2 = zip2text(my_second_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeaWm1b_pgHb","outputId":"957c9d32-c40d-4e4d-bce2-fff7a1c3b1b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["0_feeling.txt\n","1_going.txt\n","2_you.txt\n","3_i.txt\n","4_partners.txt\n"]}],"source":["i = 0 \n","for doc in resss:\n","    if i < 5:\n","        print(doc)\n","        i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyiiyYwDPdFo"},"outputs":[],"source":["#just for visualization, don't run it if you don't need it. It's very heavy \n","i = 0 \n","for doc in resss:\n","    for sent in resss[doc]:\n","        if i < 10:\n","            print(' '.join(sent))\n","        else:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hheyTkGoPc4-"},"outputs":[],"source":["#you calculate the frequency of each token \n","frequency = defaultdict(int)\n","for doc in resss:\n","    for sent in resss[doc]:\n","        for token in sent:\n","            frequency[token] += 1\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dn1lrG8aP7gm"},"outputs":[],"source":["#you keep tokens that have a frequency higher than 5\n","texts = []\n","for doc in resss:\n","    for sent in resss[doc]:\n","        keep = []\n","        for token in sent:\n","            if frequency[token] > 5:\n","                keep.append(token)\n","        texts.append(keep)\n"]},{"cell_type":"markdown","metadata":{"id":"HoMq9Vm-P8-B"},"source":["#### The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AyUS2x5P87r"},"outputs":[],"source":["# Create Dictionary\n","\n","id2word = corpora.Dictionary(texts)\n","\n","# Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"as30CPQhP84r","outputId":"5189ec99-0f7d-480e-f350-b1c0d319a817"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]]\n"]}],"source":["print(corpus[:1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkv9elxXQEsq","outputId":"2eedc2fc-da3e-40a7-ca5b-6f32d4eec513"},"outputs":[{"data":{"text/plain":["[[('big', 1),\n","  ('bit', 1),\n","  ('depressedi', 1),\n","  ('feeling', 1),\n","  ('low', 1),\n","  ('weekend', 1)]]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Human readable format of corpus (term-frequency)\n","[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"]},{"cell_type":"markdown","metadata":{"id":"1KrmCtnKQQjq"},"source":["### Building the Topic Model\n","\n","We have everything required to train the LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well.\n","\n","Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n","\n","chunksize is the number of documents to be used in each training chunk. update_every determines how often the model parameters should be updated and passes is the total number of training passes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPic9532QL4B"},"outputs":[],"source":["# Build LDA model\n","model_LDA = gensim.models.ldamodel.LdaModel(corpus=corpus,\n","                                           id2word=id2word,\n","                                           num_topics=5, \n","                                           random_state=100,\n","                                           update_every=1,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha='auto',\n","                                           per_word_topics=True)"]},{"cell_type":"markdown","metadata":{"id":"2Yaub8QBQWiy"},"source":["The above **LDA model** is built with 5 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n","\n","You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown next."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZVrB92JQM4p"},"outputs":[],"source":["# Print the first 10 keyword in each topic\n","pprint(model_LDA.print_topics())\n","doc_lda = model_LDA[corpus]\n","\n","#doc_lda[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cc3DigNaQM0Z"},"outputs":[],"source":["coherence_model_lda = CoherenceModel(model=model_LDA, texts=texts, dictionary=id2word, coherence='c_v')\n","coherence_lda = coherence_model_lda.get_coherence()\n","print('\\nCoherence Score: ', coherence_lda)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xUe57Y3QekZ"},"outputs":[],"source":["pyLDAvis.enable_notebook()\n","vis = pyLDAvis.gensim.prepare(model_LDA, corpus, id2word)\n","vis"]},{"cell_type":"markdown","metadata":{"id":"xCUfGNq-QhTZ"},"source":["So how to infer pyLDAvis’s output?\n","\n","Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n","A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n","\n","A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n","\n","Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n","\n","We have successfully built a good looking topic model.\n","\n","Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward.\n","\n","Upnext, we will improve upon this model by using Mallet’s version of LDA algorithm and then we will focus on how to arrive at the optimal number of topics given any large corpus of text."]}],"metadata":{"colab":{"name":"5_Topic_modeling.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}